{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bafb699-722b-4378-8633-e0546deb2dc1",
   "metadata": {},
   "source": [
    "# Upload Global Mangrove Watch STAC metadata\n",
    "\n",
    "Author: Henry Rodman\n",
    "\n",
    "Rather than using the more powerful (but complex) stactools-pipeline I decided to generate the STAC metadata for this collection and post it to the STAC ingestor API in a single notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.11\"\n",
    "# dependencies = [\n",
    "#     \"boto3\",\n",
    "#     \"httpx\",\n",
    "#     \"pystac>=1.12.0\",\n",
    "#     \"stactools-global-mangrove-watch==0.2.2\",\n",
    "#     \"tqdm\",\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d262060-cdf0-42ea-ab5c-a03f1f458809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "import boto3\n",
    "import httpx\n",
    "import tqdm\n",
    "from botocore.exceptions import ClientError\n",
    "from pystac import set_stac_version\n",
    "from stactools.global_mangrove_watch.constants import COLLECTION_ID\n",
    "from stactools.global_mangrove_watch.stac import create_item, create_collection\n",
    "\n",
    "set_stac_version(\"1.0.0\")\n",
    "\n",
    "# STAC ingestor URL\n",
    "INGESTOR_URL = \"https://stac-ingestor.maap-project.org\"\n",
    "\n",
    "# asset storage details\n",
    "DESTINATION_BUCKET = \"nasa-maap-data-store\"\n",
    "DESTINATION_PREFIX = \"file-staging/nasa-map/global-mangrove-watch/v3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d07f99-3286-45b8-a888-0c1f9ff117c8",
   "metadata": {},
   "source": [
    "## Dataset details\n",
    "The raw files are stored in zip archives hosted by Zenodo. To get all of the assets we need to download all of the geotiff zip archives and upload the contents to a NASA S3 bucket. This process only needs to be run once. The STAC items may consist of one or two assets depending on the year (one asset for 1996, two assets for all other years) so we need to be able to pair up the `cog` and `change_cog` assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac81e62e-cba9-4f1b-9a4b-6b753c6da742",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_URL_FORMAT = \"https://zenodo.org/records/6894273/files/gmw_v3_{group}_gtiff.zip\"\n",
    "\n",
    "BASE_YEAR = 1996\n",
    "YEARS = [\n",
    "    2007,\n",
    "    2008,\n",
    "    2009,\n",
    "    2010,\n",
    "    2015,\n",
    "    2016,\n",
    "    2017,\n",
    "    2018,\n",
    "    2019,\n",
    "    2020,\n",
    "]\n",
    "ALL_GROUPS = [str(year) for year in [BASE_YEAR] + YEARS] + [\n",
    "    f\"f{BASE_YEAR}_t{year}\" for year in YEARS\n",
    "]\n",
    "\n",
    "def parse_filename(filename: str) -> tuple[str, str]:\n",
    "    \"\"\"Parse GMW filename and return (item_id, arg_name) to be used for\n",
    "    passing cog and change_cog asset hrefs to create_item\n",
    "    \"\"\"\n",
    "    # Pattern for change files: GMW_N27W110_chng_f1996_t2020_v3.tif\n",
    "    change_pattern = r\"(GMW_[NS]\\d+[WE]\\d+)_chng_f\\d+_t(\\d+)_v3\\.tif\"\n",
    "\n",
    "    # Pattern for base files: GMW_N27W110_2020_v3.tif\n",
    "    base_pattern = r\"(GMW_[NS]\\d+[WE]\\d+)_(\\d+)_v3\\.tif\"\n",
    "\n",
    "    # Try change pattern first\n",
    "    change_match = re.match(change_pattern, filename)\n",
    "    if change_match:\n",
    "        location, year = change_match.groups()\n",
    "        base_key = f\"{location}_{year}_v3\"\n",
    "        return base_key, \"change_asset_href\"\n",
    "\n",
    "    # Try base pattern\n",
    "    base_match = re.match(base_pattern, filename)\n",
    "    if base_match:\n",
    "        location, year = base_match.groups()\n",
    "        base_key = f\"{location}_{year}_v3\"\n",
    "        return base_key, \"cog_asset_href\"\n",
    "\n",
    "    raise ValueError(f\"Unrecognized filename pattern: {filename}\")\n",
    "\n",
    "\n",
    "def upload_files_to_s3() -> None:\n",
    "    \"\"\"Download zips and upload contents to S3.\"\"\"\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "\n",
    "    for group in ALL_GROUPS:\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            zip_url = ZIP_URL_FORMAT.format(group=group)\n",
    "            zip_path = os.path.join(temp_dir, f\"gmw_v3_{group}_gtiff.zip\")\n",
    "\n",
    "            print(f\"Downloading {zip_url}\")\n",
    "            urllib.request.urlretrieve(zip_url, zip_path)\n",
    "\n",
    "            with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(temp_dir)\n",
    "\n",
    "            for root, _, files in os.walk(temp_dir):\n",
    "                for filename in sorted(files):\n",
    "                    if filename.endswith(\".tif\"):\n",
    "                        local_path = os.path.join(root, filename)\n",
    "                        s3_key = f\"{DESTINATION_PREFIX}/{filename}\"\n",
    "\n",
    "                        # Check if file already exists in S3\n",
    "                        try:\n",
    "                            s3_client.head_object(Bucket=DESTINATION_BUCKET, Key=s3_key)\n",
    "                            print(f\"File already exists in S3: {s3_key}\")\n",
    "                        except ClientError as e:\n",
    "                            if e.response[\"Error\"][\"Code\"] == \"404\":\n",
    "                                print(f\"Uploading to S3: {s3_key}\")\n",
    "                                s3_client.upload_file(\n",
    "                                    local_path, DESTINATION_BUCKET, s3_key\n",
    "                                )\n",
    "                            else:\n",
    "                                # If error is not 404, re-raise it\n",
    "                                raise\n",
    "\n",
    "        print(f\"Completed processing group: {group}\")\n",
    "\n",
    "\n",
    "def create_inventory() -> List[dict[str, str]]:\n",
    "    \"\"\"List files in S3 and create inventory dictionary grouped by item ID.\"\"\"\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    inventory = defaultdict(dict)\n",
    "\n",
    "    # Use paginator in case there are many files\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(\n",
    "        Bucket=DESTINATION_BUCKET,\n",
    "        Prefix=DESTINATION_PREFIX\n",
    "    )\n",
    "\n",
    "    for page in pages:\n",
    "        if 'Contents' not in page:\n",
    "            continue\n",
    "            \n",
    "        for obj in page['Contents']:\n",
    "            filename = os.path.basename(obj['Key'])\n",
    "            \n",
    "            if not filename.endswith('.tif'):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                base_key, arg = parse_filename(filename)\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: {e}\")\n",
    "                continue\n",
    "\n",
    "            href = f\"s3://{DESTINATION_BUCKET}/{obj['Key']}\"\n",
    "            inventory[base_key][arg] = href\n",
    "\n",
    "    return list(inventory.values())\n",
    "\n",
    "async def post_item(client: httpx.AsyncClient, item, token: str) -> None:\n",
    "    \"\"\"Post a single item to the STAC ingestor API\"\"\"\n",
    "    try:\n",
    "        response = await client.post(\n",
    "            f\"{INGESTOR_URL}/ingestions\",\n",
    "            json=item.to_dict(),\n",
    "            headers={\n",
    "                'Authorization': f'Bearer {token}',\n",
    "                'Content-Type': 'application/json',\n",
    "            },\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Error posting item: {e}\")\n",
    "        raise\n",
    "\n",
    "async def post_all_items(items: List, token: str, max_concurrent: int = 20) -> None:\n",
    "    \"\"\"Post all items concurrently with a limit on concurrent requests\"\"\"\n",
    "    async with httpx.AsyncClient(timeout=60) as client:\n",
    "        semaphore = asyncio.Semaphore(max_concurrent)\n",
    "        \n",
    "        async def bounded_post(item):\n",
    "            async with semaphore:\n",
    "                return await post_item(client, item, token)\n",
    "        \n",
    "        tasks = [bounded_post(item) for item in items]\n",
    "        \n",
    "        for task in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "            await task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c47f12f-505d-444d-8317-e70a9d86dc32",
   "metadata": {},
   "source": [
    "### Download the zips, upload COGs\n",
    "Only need to run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee67f92d-811a-412b-8e72-4a04bf04313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    upload_files_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9e72a-1e8d-4064-96e2-3bae0cada40b",
   "metadata": {},
   "source": [
    "## Create list of arguments for create_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5fa647-1752-4093-9baf-b619e3302d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16731"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory = create_inventory()\n",
    "len(inventory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6db0f5-0126-4f6f-b63b-bb939d65af37",
   "metadata": {},
   "source": [
    "## Get token for the STAC Ingestor API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d375e22b-c082-4ce4-ba4a-8dc53db589b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste MAAP SMCE AWS credentials here:\n",
    "session = boto3.Session(\n",
    "    region_name=\"us-west-2\",\n",
    ")\n",
    "client = session.client(\"secretsmanager\", region_name=\"us-west-2\")\n",
    "\n",
    "# MAAP STAC secret\n",
    "response = client.get_secret_value(\n",
    "    SecretId=\"arn:aws:secretsmanager:us-west-2:916098889494:secret:MAAP-STAC-auth-dev/MAAP-workflows-EsykqB\"\n",
    ")\n",
    "\n",
    "settings = json.loads(response[\"SecretString\"])\n",
    "\n",
    "# function to get token for STAC ingestor\n",
    "def get_token(\n",
    "    client_id: str, \n",
    "    client_secret: str, \n",
    "    domain: str,\n",
    "    scope: str\n",
    ") -> str:\n",
    "    response = httpx.post(\n",
    "        f\"{domain}/oauth2/token\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "        },\n",
    "        auth=(client_id, client_secret),\n",
    "        data={\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "            \"scope\": scope,\n",
    "        },\n",
    "    )\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except Exception:\n",
    "        raise\n",
    "\n",
    "    return response.json()[\"access_token\"]\n",
    "\n",
    "\n",
    "token = get_token(\n",
    "    client_id = settings[\"client_id\"],\n",
    "    client_secret = settings[\"client_secret\"],\n",
    "    domain = settings[\"cognito_domain\"],\n",
    "    scope = settings[\"scope\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47635c23-eabc-4163-9c6c-0fb2d97cef3a",
   "metadata": {},
   "source": [
    "## Create collection and post to ingestor API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0d6e83-5a27-4c08-b56b-820152d2417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = create_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f431d26-118e-4e29-b963-5d455c7b97ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Successfully published: global-mangrove-watch-3.0']\n"
     ]
    }
   ],
   "source": [
    "post_collection = httpx.post(\n",
    "    f\"{INGESTOR_URL}/collections\",\n",
    "    json=collection.to_dict(),\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {token}',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    ")\n",
    "print(post_collection.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d115c93-60ec-4faa-9484-ac23d4407394",
   "metadata": {},
   "source": [
    "## Create items and post to ingestor API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8985ab3c-3fe4-4649-a7ec-2abfab94ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16731/16731 [00:00<00:00, 17021.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"Feature\",\n",
      "  \"stac_version\": \"1.0.0\",\n",
      "  \"stac_extensions\": [\n",
      "    \"https://stac-extensions.github.io/projection/v1.2.0/schema.json\"\n",
      "  ],\n",
      "  \"id\": \"GMW_N00E008_1996_v3\",\n",
      "  \"geometry\": {\n",
      "    \"type\": \"Polygon\",\n",
      "    \"coordinates\": [\n",
      "      [\n",
      "        [\n",
      "          9.0,\n",
      "          -1.0\n",
      "        ],\n",
      "        [\n",
      "          9.0,\n",
      "          0.0\n",
      "        ],\n",
      "        [\n",
      "          8.0,\n",
      "          0.0\n",
      "        ],\n",
      "        [\n",
      "          8.0,\n",
      "          -1.0\n",
      "        ],\n",
      "        [\n",
      "          9.0,\n",
      "          -1.0\n",
      "        ]\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  \"bbox\": [\n",
      "    8.0,\n",
      "    -1.0,\n",
      "    9.0,\n",
      "    0.0\n",
      "  ],\n",
      "  \"properties\": {\n",
      "    \"proj:code\": \"EPSG:4326\",\n",
      "    \"proj:geometry\": {\n",
      "      \"type\": \"Polygon\",\n",
      "      \"coordinates\": [\n",
      "        [\n",
      "          [\n",
      "            9.0,\n",
      "            -1.0\n",
      "          ],\n",
      "          [\n",
      "            9.0,\n",
      "            0.0\n",
      "          ],\n",
      "          [\n",
      "            8.0,\n",
      "            0.0\n",
      "          ],\n",
      "          [\n",
      "            8.0,\n",
      "            -1.0\n",
      "          ],\n",
      "          [\n",
      "            9.0,\n",
      "            -1.0\n",
      "          ]\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"proj:bbox\": [\n",
      "      8.0,\n",
      "      -1.0,\n",
      "      9.0,\n",
      "      0.0\n",
      "    ],\n",
      "    \"proj:shape\": [\n",
      "      4500,\n",
      "      4500\n",
      "    ],\n",
      "    \"proj:transform\": [\n",
      "      0.00022222222222222223,\n",
      "      0.0,\n",
      "      8.0,\n",
      "      0.0,\n",
      "      -0.00022222222222222223,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ],\n",
      "    \"proj:epsg\": 4326,\n",
      "    \"datetime\": \"1996-12-31T00:00:00Z\"\n",
      "  },\n",
      "  \"links\": [],\n",
      "  \"assets\": {\n",
      "    \"cog\": {\n",
      "      \"href\": \"s3://nasa-maap-data-store/file-staging/nasa-map/global-mangrove-watch/v3/GMW_N00E008_1996_v3.tif\",\n",
      "      \"type\": \"image/tiff; application=geotiff; profile=cloud-optimized\",\n",
      "      \"title\": \"Mangrove cover\",\n",
      "      \"description\": \"Gridded estimate of mangrove cover\",\n",
      "      \"roles\": [\n",
      "        \"data\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"collection\": \"global-mangrove-watch-3.0\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "items = []\n",
    "for args in tqdm.tqdm(inventory):\n",
    "    item = create_item(**args)\n",
    "    item.collection_id = COLLECTION_ID\n",
    "    items.append(item)\n",
    "\n",
    "print(json.dumps(items[0].to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3bfa0c-4674-4ece-86c2-8179592bdb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16731/16731 [04:09<00:00, 67.00it/s]\n"
     ]
    }
   ],
   "source": [
    "await post_all_items(items, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7875e2-5075-4177-a9e7-bc856b74fbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
